In this section we review the related work with respect to relevant frameworks and concepts used in this paper for CDR based customer positioning and its implementation in a distributed environment.

\subsection{Trajectory mining}
%http://crpit.com/confpapers/CRPITV137Wang.pdf
For more accurate customer localization the individual observations of user location can be grouped as set of trajectories. In this way we learn more about the location of the user by considering the semantics of trajectories and the related work done in the field of trajectory mining. Trajectory similarity is a key concept used in this paper for evaluating the quality of event positioning.

Trajectory mining has been widely researched during the last decades. Since trajectories represent a moving object's location history, there are plenty of use cases where trajectory mining can be successfully applied.  Due the fact that most mobile phones are now able to track GPS, there is more and more data available for this domain of data mining. There is however still no consensus on what dissimilarity or distance measure to use when comparing trajectories.

A trajectory reflects the motion history of a moving object. In practice trajectory is not continuous due to the limited sampling capability, therefore one reasonable approach is to consider trajectories as a sequence of points.

\newdef{definition}{Definition}
\begin{definition}
A point $P(x,y)$\nomenclature{$P(x,y)$}{A point given as a pair of latitude and longitude, representing a geographical location.}can be defined as a pair of latitude $y$ and longitude $x$ values representing a geographical location.
\end{definition}

\begin{definition}
A trajectory $T$\nomenclature{$T$}{Trajectory given as  time-stamped sequence of points with length $n$.} with length $n$ is defined as a time-stamped sequence of its consecutive points: \[T={(t_{1},P_{1}), (t_{2},P_{2}), .. (t_{n},P_{n}}), T \in M\]
where $\mathcal{M}$\nomenclature{$\mathcal{M}$}{A set of possible trajectories.} is the set of possible trajectories.
\end{definition}

\section{Trajectory similarity}
If we consider trajectories as a sequence of points, the distance of two trajectories can be considered as an aggregate of distances between the points of the compared trajectories. The way of aggregation can determine the computation time, accuracy and sensitivity of the distance measure.

According to Magdy et al. (\cite{traj-sim-rev}) the existing trajectory distance measures can be classified into two classes: 
\begin{itemize}
    \item \textit{spatial} dissimilarity that aims at finding similarly  shaped trajectories while ignoring the temporal dimension, e.g. Euclidean distance
    \item \textit{spatio-temporal} dissimilarity that considers both the spatial and the temporal dimensions, such as dynamic time-warping (DTW) method
\end{itemize}

In \cite{traj-sim} the authors attempt to provide an experimental study on comparing the six most widely used distance measures. They base the study on a large set of GPS trajectories collected by taxis in Beijing and apply different transformation on top of them. Then they compare the original trajectories - using different dissimilarity measures - to the transformed ones with the assumption that the trajectories with less transformation should be more similar to the originals. One of the dissimilarity measures they used is Euclidean distance, which is a metric measure, also known as L2-norm and according to their results it turned out to be sensitive to noise, sampling rate, but robust to shifts in the trajectory.

Although Euclidean distance relies on the fact that time series and trajectories have similar representations, it does not consider the time-stamps associated with the points in the trajectory. Also the two trajectories need to have the same number of points. Apart from these limitations Euclidean distance is still one of the most commonly used distance measures, since it scales well with large data-sets and is relatively simple. 

On the other hand, DTW is a non-metric measure that provides more flexibility in terms of the length and sampling rate of the trajectories and takes the time-stamps into account. However it is more I/O and time consuming. For low quality GPS data the authors propose longest common sub-sequence (LCSS) method that is also used as a string similarity metric.

Most of the above mentioned measures depend on the definition of spatial distance between two points. One of the most common spatial distance between two points can be given with the Haversine formula \cite{haversine}, which  defines the great-circle distance in kilometers between two points on a sphere given their longitudes and latitudes.

\begin{definition}
A for any two points on a sphere, the Haversine formula determines the spatial distance between the two points denoted with $d$\nomenclature{$d$}{Spatial distance between two points.} according to \cite{haversine}:
    \[\Delta_{x} = x_{2} - x_{1}\]
    \[\Delta_{y} = y_{2} - y_{1}\]
    \[a = (\sin(\Delta_{y}/2))^2 + \cos{(y_{1})} * \cos{(y_{2})} * (\sin{(\Delta_{x}/2)})^2 \]
    \[c = 2 * \arcsin{(\min{1,\sqrt{a}})}\]
    \[d(P_{1}, P_{2}) = R * c\]
    where $R$ is the radius of the Earth and $x_{i}, y_{i}$ is the longitude, latitude values of $P_{i}$ in radians.
\end{definition}

